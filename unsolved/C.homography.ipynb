{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM2000 Lab 2.C. Homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was adapted from OpenCV tutorials.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://learnopencv.com\">View on learnopencv.com</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Homography of an image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Code assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run homography for a frame of a hockey and amrican football play. Save your results as './homography/homography_hockey.jpg' and './homography/homography_football.jpg'.  \n",
    "Then, choose another sport where you think the same technique could work, find a picture of the field and a frame of a play, and perform the homography. Save your results as './homography/homography_sport.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "drawing = False  # true if mouse is pressed\n",
    "src_x, src_y = -1, -1\n",
    "dst_x, dst_y = -1, -1\n",
    "\n",
    "src_list = []\n",
    "dst_list = []\n",
    "\n",
    "# Define the frame and field file paths for the homography\n",
    "frame_path = './homography/frame_hockey.jpg'\n",
    "field_path = './homography/field_hockey.jpg'\n",
    "homography_path = './homography/homography_hockey.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse callback functions\n",
    "def select_points_src(event, x, y, flags, param):\n",
    "    '''mouse callback function'''\n",
    "    global src_x, src_y, drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        src_x, src_y = x, y\n",
    "        cv2.circle(src_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "def select_points_dst(event, x, y, flags, param):\n",
    "    '''mouse callback function'''\n",
    "    global dst_x, dst_y, drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        dst_x, dst_y = x, y\n",
    "        cv2.circle(dst_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging functions\n",
    "def get_plan_view(src, dst, src_list, dst_list):\n",
    "    src_pts = np.array(src_list).reshape(-1, 1, 2)\n",
    "    dst_pts = np.array(dst_list).reshape(-1, 1, 2)\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    print(\"H:\")\n",
    "    print(H)\n",
    "    plan_view = cv2.warpPerspective(src, H, (dst.shape[1], dst.shape[0]))\n",
    "    return plan_view\n",
    "\n",
    "\n",
    "def merge_views(src, dst, src_list, dst_list):\n",
    "    plan_view = get_plan_view(src, dst, src_list, dst_list)\n",
    "    for i in range(0, dst.shape[0]):\n",
    "        for j in range(0, dst.shape[1]):\n",
    "            if (plan_view.item(i, j, 0) == 0 and\n",
    "               plan_view.item(i, j, 1) == 0 and\n",
    "               plan_view.item(i, j, 2) == 0):\n",
    "                plan_view.itemset((i, j, 0), dst.item(i, j, 0))\n",
    "                plan_view.itemset((i, j, 1), dst.item(i, j, 1))\n",
    "                plan_view.itemset((i, j, 2), dst.item(i, j, 2))\n",
    "    return plan_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the code below, you will be prompted with 2 windows: the field and the frame.  \n",
    "Mark a point in the video, then mark the same point in the field, and press key 's' to save the point to the homography. The code \"remembers\" only the last point pressed at each window when performing the save operation.  \n",
    "Repeat for at least 4 points, then press key 'm' to perform the homography.  \n",
    "Then, press key 'q' to quit and release resources. Wait a few seconds before running the next cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark a point in the video, then mark the same point in the field, and press key s\n",
      "Repeat for at least 4 points.\n",
      "...saving points\n",
      "src points:\n",
      "[[1699, 817]]\n",
      "dst points:\n",
      "[[562, 96]]\n",
      "...saving points\n",
      "src points:\n",
      "[[1699, 817], [851, 954]]\n",
      "dst points:\n",
      "[[562, 96], [476, 136]]\n",
      "...saving points\n",
      "src points:\n",
      "[[1699, 817], [851, 954], [854, 494]]\n",
      "dst points:\n",
      "[[562, 96], [476, 136], [475, 8]]\n",
      "...saving points\n",
      "src points:\n",
      "[[1699, 817], [851, 954], [854, 494], [1833, 481]]\n",
      "dst points:\n",
      "[[562, 96], [476, 136], [475, 8], [594, 10]]\n",
      "Press m to merge.\n",
      "...merging views\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "Press q to quite and release resources.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homography for an image\n",
    "print(\"Mark a point in the video, then mark the same point in the field, and press key s\")\n",
    "print(\"Repeat for at least 4 points.\")\n",
    "\n",
    "src = cv2.imread(frame_path, -1)\n",
    "src_copy = src.copy()\n",
    "cv2.namedWindow('src')\n",
    "cv2.moveWindow(\"src\", 80, 80)\n",
    "cv2.setMouseCallback('src', select_points_src)\n",
    "\n",
    "dst = cv2.imread(field_path, -1)\n",
    "dst_copy = dst.copy()\n",
    "cv2.namedWindow('dst')\n",
    "cv2.moveWindow(\"dst\", 780, 80)\n",
    "cv2.setMouseCallback('dst', select_points_dst)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('src', src_copy)\n",
    "    cv2.imshow('dst', dst_copy)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('s'):\n",
    "        print('...saving points')\n",
    "        cv2.circle(src_copy, (src_x, src_y), 5, (0, 255, 0), -1)\n",
    "        cv2.circle(dst_copy, (dst_x, dst_y), 5, (0, 255, 0), -1)\n",
    "        src_list.append([src_x, src_y])\n",
    "        dst_list.append([dst_x, dst_y])\n",
    "        print(\"src points:\")\n",
    "        print(src_list)\n",
    "        print(\"dst points:\")\n",
    "        print(dst_list)\n",
    "\n",
    "        if len(src_list) >= 4 and len(dst_list) >= 4:\n",
    "            print(\"Press m to merge.\")\n",
    "    elif k == ord('m'):\n",
    "        print('...merging views')\n",
    "        merge = merge_views(src, dst, src_list, dst_list)\n",
    "        cv2.imwrite(homography_path, merge)\n",
    "        cv2.imshow(\"merge\", merge)\n",
    "        print(\"Press q to quite and release resources.\")\n",
    "    elif k == 27 or k == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Written assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using different points in the field to perform the homography. Identify the limitations and write a paragraph with your reflections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Homography of a video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Code assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code to use the homography matrix computed for the first frame of the video and perform the homography for the whole video. Do it for both hockey and football.  \n",
    "Save your results as './homography/homography_hockey_static.gif' and './homography/homography_football_static.gif'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video path for the homography\n",
    "video_path = './homography/video_hockey.mp4'\n",
    "homography_name = './homography/homography_hockey_static.gif'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the code below, you will be prompted with a window showing the result of the homography in slow motion.   \n",
    "Wait for the animation to finish. Then, press key 'q' to quit and release resources. Wait a few seconds before running the next cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Merging views\n",
      "Wait for the animation of the tracking. Then press Enter to finish.\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 7.00464539e-01  1.00915288e+00  1.36703243e+02]\n",
      " [ 2.49445866e-02  1.00812757e+00 -4.98544280e+02]\n",
      " [ 6.53228990e-04  2.10287297e-03  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('...Merging views')\n",
    "# Store merged frames\n",
    "merged_frames = []\n",
    "# Read video\n",
    "video = cv2.VideoCapture(video_path)\n",
    "# Get frame count and rate\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_rate = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# Read field image\n",
    "dst = cv2.imread(field_path, -1)\n",
    "print(\"Wait for the animation of the tracking. Then press Enter to finish.\")\n",
    "\n",
    "i=0\n",
    "while True:\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Read video frame.\n",
    "    ok, src = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Get the points for the homography\n",
    "    merge = merge_views(src, dst, src_list, dst_list)  \n",
    "    # Display homography   \n",
    "    cv2.imshow(\"merge\", merge)\n",
    "    # Store frames\n",
    "    merged_frames.append(merge)\n",
    "\n",
    "    # Exit if the 'q' key is pressed\n",
    "    if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    i+=1\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "video.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./homography/homography_hockey_static.gif saved!\n"
     ]
    }
   ],
   "source": [
    "from tools import to_gif\n",
    "\n",
    "to_gif(merged_frames,int(1000/frame_rate), homography_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Written assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the correctness of the predictions and the confidence scores. Try to establish a threshold. Write down your reflections and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Homography of a video with moving camera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Code assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the moving camera, we perform object tracking of the points used in the homography and recompute the matrix for every frame. Run the code that does point tracking and homography computation. Do it for both hockey and football.  \n",
    "Save your results as './homography/homography_hockey_dynamic.gif' and './homography/homography_football_dynamic.gif'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "drawing = False  # true if mouse is pressed\n",
    "src_x, src_y = -1, -1\n",
    "dst_x, dst_y = -1, -1\n",
    "\n",
    "src_list = []\n",
    "dst_list = []\n",
    "\n",
    "# Define the frame and field file paths for the homography\n",
    "video_path = './homography/video_hockey.mp4'\n",
    "field_path = './homography/field_hockey.jpg'\n",
    "homography_name = './homography/homography_hockey_dynamic.gif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a OpenCV tracker (and it's the piece that will fail without opencv-contrib-python).  \n",
    "You can test the 3 different types and read more about them [here](https://learnopencv.com/object-tracking-using-opencv-cpp-python/). I found KCF to be the best in this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tracker\n",
    "# see https://github.com/spmallick/learnopencv/blob/master/tracking/tracker.py\n",
    "# and https://learnopencv.com/object-tracking-using-opencv-cpp-python/\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "tracker_types = ['MIL','KCF','CSRT']\n",
    "tracker_type = tracker_types[1]\n",
    "def create_tracker(tracker_type):\n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse callback functions\n",
    "def select_points_dst(event, x, y, flags, param, dst_copy):\n",
    "    '''mouse callback function'''\n",
    "    global dst_x, dst_y, drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        dst_x, dst_y = x, y\n",
    "        cv2.circle(dst_copy, (x, y), 5, (0, 0, 255), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging functions\n",
    "def get_plan_view(src, dst, src_list, dst_list):\n",
    "    src_pts = np.array(src_list).reshape(-1, 1, 2)\n",
    "    dst_pts = np.array(dst_list).reshape(-1, 1, 2)\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    print(\"H:\")\n",
    "    print(H)\n",
    "    plan_view = cv2.warpPerspective(src, H, (dst.shape[1], dst.shape[0]))\n",
    "    return plan_view\n",
    "\n",
    "\n",
    "def merge_views(src, dst, src_list, dst_list):\n",
    "    plan_view = get_plan_view(src, dst, src_list, dst_list)\n",
    "    for i in range(0, dst.shape[0]):\n",
    "        for j in range(0, dst.shape[1]):\n",
    "            if (plan_view.item(i, j, 0) == 0 and\n",
    "               plan_view.item(i, j, 1) == 0 and\n",
    "               plan_view.item(i, j, 2) == 0):\n",
    "                plan_view.itemset((i, j, 0), dst.item(i, j, 0))\n",
    "                plan_view.itemset((i, j, 1), dst.item(i, j, 1))\n",
    "                plan_view.itemset((i, j, 2), dst.item(i, j, 2))\n",
    "    return plan_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track funtion to track the points for the frame-by-frame homography\n",
    "def track_point(video_path, tracker):\n",
    "\n",
    "    centers = []\n",
    "    field_centers = []\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print ('Cannot read video file')\n",
    "        sys.exit()\n",
    "\n",
    "    # Select bounding box\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Draw center point\n",
    "    center_point_x = int(bbox[0]+ 0.5*bbox[2])\n",
    "    center_point_y = int(bbox[1] + 0.5*bbox[3])\n",
    "    center = (center_point_x,center_point_y)\n",
    "    cv2.circle(frame, center, 2, (0,0,255), -1)\n",
    "    # Store center point\n",
    "    centers.append(center)\n",
    "\n",
    "    # Pause 1000 ms\n",
    "    key = cv2.waitKey(1000)\n",
    "    print(\"Wait for the animation of the tracking. Then press Enter to continue.\")\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    "\n",
    "    while True:\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        if not ok:\n",
    "            break\n",
    "            \n",
    "        # Start timer\n",
    "        timer = cv2.getTickCount()\n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    "\n",
    "        # Calculate Frames per second (FPS)\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "\n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "            # Draw center point\n",
    "            center_point_x = int(bbox[0]+ 0.5*bbox[2])\n",
    "            center_point_y = int(bbox[1] + 0.5*bbox[3])\n",
    "            center = (center_point_x,center_point_y)\n",
    "            cv2.circle(frame, center, 2, (0,0,255), -1)\n",
    "            # Store center point\n",
    "            centers.append(center)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "        # Display tracker type on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2) \n",
    "        \n",
    "        # Display FPS on frame\n",
    "        cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2) \n",
    "\n",
    "        # Display result\n",
    "        cv2.imshow(\"video\", frame)\n",
    "\n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(200) & 0xff\n",
    "        if k == 27 or k == ord('q'): break\n",
    "\n",
    "    # Release the video capture object and close windows\n",
    "    video.release()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    print(f'centers: {centers}')\n",
    "\n",
    "    # Open field\n",
    "    dst = cv2.imread(field_path, -1)\n",
    "    dst_copy = dst.copy()\n",
    "    cv2.namedWindow('dst')\n",
    "    cv2.moveWindow(\"dst\", 780, 80)\n",
    "    callback = partial(select_points_dst, dst_copy=dst_copy)\n",
    "    cv2.setMouseCallback('dst', callback)\n",
    "    \n",
    "    print(\"Single click to select the point in the field that best matches the tracked point. Press Enter to continue.\")\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow('dst',dst_copy)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 13 and (dst_x != -1 and dst_y != -1):\n",
    "            cv2.circle(dst_copy, (dst_x, dst_y), 5, (0, 255, 0), -1)\n",
    "            field_center_list = [(dst_x, dst_y)]*len(centers)\n",
    "            field_centers.extend(field_center_list)\n",
    "            print(f'field centers: {field_centers}')\n",
    "            cv2.waitKey(200)  # Wait for 500ms\n",
    "            break\n",
    "        elif k == 27 or k == ord('q'):\n",
    "            break\n",
    "\n",
    "    print(\"Press Enter to continue\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    return centers, field_centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the code below, a window will pop up with the first frame of the video. You should select the region of interest by drawing a rectangle from the top left to the bottom right corner. You can re-draw it multiple times. When happy with the result, press Enter and the tracking will start. Wait for the animation to finish and make sure the point has been tracked in every frame of the video. Then, press Enter to continue.  \n",
    "A new window will pop up with the field. Single click the field to select the point in the field that best matches the tracked point. Press Enter to save the point.  \n",
    "Press Enter to continue to the next point until n_points, where n>=4 for the homography.\n",
    "When finished, press any key on your keyboard to close the window and release the resources to be able to run the code again, or continue running the next blocks (you need to have the video window selected on that step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Wait for the animation of the tracking. Then press Enter to continue.\n",
      "centers: [(1701, 815), (1701, 815), (1690, 816), (1677, 815), (1664, 814), (1649, 813), (1640, 814), (1627, 813), (1616, 814), (1605, 813), (1594, 812), (1581, 811), (1572, 810), (1559, 809), (1548, 810), (1539, 809)]\n",
      "Single click to select the point in the field that best matches the tracked point. Press Enter to continue.\n",
      "field centers: [(562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95), (562, 95)]\n",
      "Press Enter to continue\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Wait for the animation of the tracking. Then press Enter to continue.\n",
      "centers: [(849, 943), (849, 943), (838, 942), (825, 941), (814, 942), (801, 941), (790, 942), (777, 941), (768, 942), (757, 941), (746, 942), (735, 941), (724, 942), (713, 941), (704, 942), (691, 941)]\n",
      "Single click to select the point in the field that best matches the tracked point. Press Enter to continue.\n",
      "field centers: [(476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133), (476, 133)]\n",
      "Press Enter to continue\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Wait for the animation of the tracking. Then press Enter to continue.\n",
      "centers: [(850, 476), (850, 476), (837, 476), (825, 476), (813, 476), (801, 476), (790, 477), (777, 477), (766, 477), (754, 478), (743, 478), (733, 477), (722, 477), (710, 477), (699, 477), (688, 477)]\n",
      "Single click to select the point in the field that best matches the tracked point. Press Enter to continue.\n",
      "field centers: [(475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9), (475, 9)]\n",
      "Press Enter to continue\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Wait for the animation of the tracking. Then press Enter to continue.\n",
      "centers: [(1830, 468), (1830, 468), (1816, 468), (1802, 468), (1789, 467), (1776, 467), (1764, 467), (1751, 466), (1739, 466), (1727, 466), (1715, 466), (1704, 465), (1692, 464), (1681, 463), (1669, 463), (1658, 463)]\n",
      "Single click to select the point in the field that best matches the tracked point. Press Enter to continue.\n",
      "field centers: [(593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9), (593, 9)]\n",
      "Press Enter to continue\n"
     ]
    }
   ],
   "source": [
    "# Run the detection and homography\n",
    "n_points = 4\n",
    "centers_h = []\n",
    "field_centers_h = []\n",
    "\n",
    "for points in range(n_points):\n",
    "\n",
    "    tracker = create_tracker(tracker_type)\n",
    "    centers, field_centers = track_point(video_path, tracker)\n",
    "    centers_h.append(centers)\n",
    "    field_centers_h.append(field_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4, 2)\n",
      "(16, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "# Change shapes to (frame, point, coordinates)\n",
    "centers_h_arr = np.array(centers_h)\n",
    "centers_h_arr = centers_h_arr.transpose(1,0,2)\n",
    "print(centers_h_arr.shape)\n",
    "field_centers_h_arr = np.array(field_centers_h)\n",
    "field_centers_h_arr = field_centers_h_arr.transpose(1,0,2)\n",
    "print(field_centers_h_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below iterates the frames of the video and uses the previous caluclated homography matrices to perform the homography frame by frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Merging views\n",
      "Wait for the animation of the tracking. Then press Enter to finish.\n",
      "H:\n",
      "[[ 5.36659364e-01  7.60658986e-01  2.05306581e+02]\n",
      " [ 1.05055742e-02  7.83107673e-01 -3.62295587e+02]\n",
      " [ 4.69938737e-04  1.58692151e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.36659364e-01  7.60658986e-01  2.05306581e+02]\n",
      " [ 1.05055742e-02  7.83107673e-01 -3.62295587e+02]\n",
      " [ 4.69938737e-04  1.58692151e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.59454424e-01  7.85975893e-01  2.02405865e+02]\n",
      " [ 1.09388343e-02  8.03896213e-01 -3.72014310e+02]\n",
      " [ 4.98947537e-04  1.64274514e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.62705255e-01  7.99092501e-01  2.04345103e+02]\n",
      " [ 1.10323122e-02  8.10830293e-01 -3.75182130e+02]\n",
      " [ 5.01771805e-04  1.66878878e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.47156982e-01  7.74350442e-01  2.14545556e+02]\n",
      " [ 1.15210408e-02  7.91238690e-01 -3.66518802e+02]\n",
      " [ 4.84344569e-04  1.61845745e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.37379060e-01  7.58913519e-01  2.21799314e+02]\n",
      " [ 1.13280026e-02  7.79740074e-01 -3.61027174e+02]\n",
      " [ 4.73561699e-04  1.58471645e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.59318553e-01  7.93464010e-01  2.17729614e+02]\n",
      " [ 1.25929267e-02  8.03168156e-01 -3.73390860e+02]\n",
      " [ 4.99996025e-04  1.65706762e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.64928325e-01  7.98097140e-01  2.20786351e+02]\n",
      " [ 1.35241017e-02  8.07037492e-01 -3.75751738e+02]\n",
      " [ 5.08792103e-04  1.66675736e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.60994476e-01  7.83793724e-01  2.27000494e+02]\n",
      " [ 1.33953553e-02  7.96891930e-01 -3.70851289e+02]\n",
      " [ 5.05904005e-04  1.63971620e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.66708618e-01  7.91504290e-01  2.29702678e+02]\n",
      " [ 1.43631852e-02  8.04527447e-01 -3.75776992e+02]\n",
      " [ 5.13879214e-04  1.65731859e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.48841903e-01  7.77941282e-01  2.38375559e+02]\n",
      " [ 1.39849692e-02  7.89728739e-01 -3.68592350e+02]\n",
      " [ 4.90691289e-04  1.62890906e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.40492060e-01  7.61411822e-01  2.44416773e+02]\n",
      " [ 1.37628007e-02  7.76812729e-01 -3.61608609e+02]\n",
      " [ 4.82201025e-04  1.59285248e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.42204212e-01  7.76077299e-01  2.46862284e+02]\n",
      " [ 1.46362261e-02  7.82346102e-01 -3.64637597e+02]\n",
      " [ 4.83001871e-04  1.62364385e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.35595232e-01  7.53648086e-01  2.54239923e+02]\n",
      " [ 1.51979161e-02  7.69426563e-01 -3.58973256e+02]\n",
      " [ 4.78777037e-04  1.57799898e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.32063806e-01  7.40384347e-01  2.59909373e+02]\n",
      " [ 1.50540422e-02  7.60036952e-01 -3.54397522e+02]\n",
      " [ 4.76240137e-04  1.55295896e-03  1.00000000e+00]]\n",
      "H:\n",
      "[[ 5.42571060e-01  7.73082603e-01  2.58947130e+02]\n",
      " [ 1.54148340e-02  7.78793905e-01 -3.63123850e+02]\n",
      " [ 4.87198549e-04  1.61880144e-03  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform and display the homography from the saved points\n",
    "print('...Merging views')\n",
    "# Store merged frames\n",
    "merged_frames = []\n",
    "# Read video\n",
    "video = cv2.VideoCapture(video_path)\n",
    "# Get frame count and rate\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_rate = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# Read field image\n",
    "dst = cv2.imread(field_path, -1)\n",
    "print(\"Wait for the animation of the tracking. Then press Enter to finish.\")\n",
    "\n",
    "i=0\n",
    "while True:\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Read video frame.\n",
    "    ok, src = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Get the points for the homography\n",
    "    src_list = centers_h_arr[i].tolist()\n",
    "    dst_list = field_centers_h_arr[i].tolist()\n",
    "    merge = merge_views(src, dst, src_list, dst_list)  \n",
    "    # Display homography   \n",
    "    cv2.imshow(\"merge\", merge)\n",
    "    # Store frames\n",
    "    merged_frames.append(merge)\n",
    "\n",
    "    # Exit if the 'q' key is pressed\n",
    "    if cv2.waitKey(200) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    i+=1\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "video.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./homography/homography_hockey_dynamic.gif saved!\n"
     ]
    }
   ],
   "source": [
    "from tools import to_gif\n",
    "\n",
    "to_gif(merged_frames,int(1000/frame_rate), homography_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Code assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose another sport where you think the same technique could work, find a picture of the field and a short video of a play, and perform the homography. Save your results as './homography/homography_sport_dynamic.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Written assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about how this technology could be applied in the sport that you chose on task 3.2. Write a paragraph with your reflections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(For all)\n",
    "\n",
    "Now you are already familiar with multiple tracking algorithms, choose one of the videos provided (hockey or american football) and perform the homography while tracking the position of one or more players. Plot the positions of the players that you track on the image of the field as dots of different colors. Save a gif displaying the dots moving on the field as './homography/bonus_task.gif'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm2000-video-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
